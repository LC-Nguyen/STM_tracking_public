{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook will be instructions how to tune parameters and get the image data into a good state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the imports to get the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from analysis_stm import MotionAnalyzer,ExpMetaData, DiffusionPlotter\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "import trackpy as tp\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sxmreader import SXMReader\n",
    "import matplotlib as mpl\n",
    "import scipy\n",
    "from sxmreader import SXMReader\n",
    "from PIL import Image\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "%matplotlib inline\n",
    "import ipywidgets as widgets \n",
    "import matplotlib.animation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import frame_correct as fc\n",
    "import pims\n",
    "import yaml\n",
    "#import ffmpeg\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next cell loads all the parameters: after tuning them, I suggest editing this initial cell so you don't have to repeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS IS TEST DATA, NOT NECCESSARILY ACCURATE\n",
    "\n",
    "#Set the default parameter for the scan area correction from frame_correct\n",
    "frame_drift_par={\n",
    "                   'steps':2, #How many loops it runs: 1 is fastest, 2 is more consistent, 3+ is pretty unneccessary is generally the same as 2.\n",
    "                   'adjust':[[],[]], #Manual corrections, empty for default. \n",
    "                   'output_crop':200, #The output image size with grey padding: Needs to be large enough to account for the frame shifting\n",
    "} \n",
    "emds=[] #Creates list of metadata\n",
    "frame_drift_pars=[] #Creates list of frame_correct parameters\n",
    "tears=[] #Creates list of visual tears tears\n",
    "params_=[] # Creates list of trackpy parameters \n",
    "\n",
    "\n",
    "Vg=60 # Gate voltage: Used for labeling an plotting\n",
    "FOLDER = \"test_sets/15.5K\" #Folder where the data is \n",
    "voltages_temperatures = np.array([15.5,15.6]) #Temperatures or source drain voltage: Can have multiple\n",
    "\n",
    "sets = [ range(138, 145),range(145, 156)] #The ranges of images (must be formated as Image_123.sxm.)\n",
    "#Corresponding to each voltage/temeprature\n",
    "emd = ExpMetaData(sets, Vg, voltages_temperatures, FOLDER) #create object to store this data\n",
    "\n",
    "#trackpy parameters \n",
    "params = {\n",
    "    'molecule_size': 7, #size of circles to consider a molecule\n",
    "    'min_mass': 2, #measure of the total brightness in each circle \n",
    "    'max_mass': 100, #filtering we added\n",
    "    'min_size': 1,  #filtering we added\n",
    "    'max_ecc': 1, #Filtering we aded\n",
    "    'separation': 1, #for tp.locate\n",
    "    'search_range': 50, #for tp.link\n",
    "    'adaptive_stop': 1,#for tp.link\n",
    "    'diffusion_time': 10,#for time scale of data: time between each frame\n",
    "    'threshold': 0.12, #lower bound of intensity that trackpy sees: also necessary to ignore grey padding.\n",
    "} \n",
    "\n",
    "#appending everything to the lists\n",
    "frame_drift_pars.append([frame_drift_par,frame_drift_par])\n",
    "emds.append(emd)\n",
    "tears.append([None,None])\n",
    "#Should be \n",
    "#tears.append([[[0,64]],[[3,61]]])\n",
    "\n",
    "params_.append(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell organizes the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms=[] #lists of datasets\n",
    "\n",
    "for i,emd in enumerate(emds):\n",
    "    with open('params.yaml', 'w') as f:\n",
    "        yaml.dump(params_[i], f, default_flow_style=False)\n",
    "    m = MotionAnalyzer(emd.sets, emd.voltages_temperatures,\n",
    "                   emd.folder,frame_drift_par=frame_drift_pars[i], heater=True, drift_correction = True,rotation_check=True,correct='lines')\n",
    "    ms.append(m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A very common error that happens is if the data you inputted does not actually exist or is incorrectly named.\n",
    "The error message will have something like assert os.path.exists(self.filename) followed by an Assertion Error.\n",
    "The following cell runs a check to see if the files are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "empty=[]\n",
    "for m in ms:\n",
    "    # Path to the folder with your files\n",
    "    for dataset in m.SXM_PATH:\n",
    "        for path in dataset:\n",
    "            if not os.path.exists(path):\n",
    "                print(f'{path} does not exists')\n",
    "                empty.append(path)\n",
    "if len(empty)==0:\n",
    "    print(\"All files present\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next cell plots all the images currently loaded, sorted by data set and temperature, in order to indentify any visual tears\n",
    " In the test dataset given, there are tears in the first temperature on frame 0 at line 64, and on the second temperature at frame 3 at line 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this, and USE THIS TO FIND TEARS\n",
    "for i,m in enumerate(ms):\n",
    "    fig=plt.figure(figsize=(13,0.1))\n",
    "    plt.title(f'dataset {i}')\n",
    "    for temp_set, path in enumerate(m.SXM_PATH):\n",
    "        fig=plt.figure(figsize=(10,0.1))\n",
    "        plt.title(f'Temperature set {temp_set}')\n",
    "        frames = SXMReader(path, correct='lines')\n",
    "        frames_=[]\n",
    "        for frame in frames:\n",
    "            frames_.append(frame)\n",
    "        frames=frames_\n",
    "        tear=tears[i][temp_set]\n",
    "        if tear is not None:\n",
    "            for correction in tear:\n",
    "                frame_new=np.array(frames[correction[0]])\n",
    "                frame_new[correction[1],:]=(frame_new[correction[1]+1,:]+frame_new[correction[1]-1,:])/2\n",
    "                frame_new = (frame_new - frame_new.min()) / (frame_new.max() - frame_new.min())  # scale to [0, 1]\n",
    "                frame_new = frame_new * 2 - 1    \n",
    "                frame_new = pims.Frame(frame_new, frame_no=correction[0])\n",
    "                frames[correction[0]]=frame_new\n",
    "        for frame_number in range(len(frames)):\n",
    "            fig,ax=plt.subplots()\n",
    "            plt.title(f'frame {frame_number}')\n",
    "            ax.xaxis.set_minor_locator(mpl.ticker.MultipleLocator(1))\n",
    "            ax.yaxis.set_major_locator(mpl.ticker.MultipleLocator(5))\n",
    "\n",
    "            \n",
    "            ax.yaxis.set_minor_locator(mpl.ticker.MultipleLocator(1)) \n",
    "            plt.imshow(frames[frame_number])\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the Tears\n",
    "Obviously, we don't want those tears in our data. We record where they are so they can be fixed. \n",
    "Once you identify the tears, you can run this cell and then the previous cell to see if they were properly corrected.\n",
    "I suggest going back to the beggining afterword and replacing tears.append(None,None)\n",
    "With the correct tears.append([[[0,64]],[[3,61]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONAL: Fix tears here:\n",
    "index=0 #The dataset of interest\n",
    "#The format is like this:\n",
    "#tears[index]=[tears for first temperature, tears for second temperature...]\n",
    "#where tears for first temperature= [[frame,row],[frame 2,row 2]...]\n",
    "tears[0]=[[[0,64]],[[3,61]]]\n",
    "#rerun above cell to check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing search parameters\n",
    "This is the most important (and also tedious) step. We optimize the search parameters to pick up only real particles.\n",
    "play with molecule_size and the kwargs (key word arguments) to see what works. You want to find all real particles and not pick up false particles. The parameters at the beggining are the ones I used and found satisfactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTANT for testing\n",
    "###### Optimize Parameters\n",
    "plt.figure()\n",
    "index=0 #Choose data set\n",
    "temp_index=0 #Choose temperature set\n",
    "path = ms[index].SXM_PATH[temp_index]\n",
    "frames = SXMReader(path, correct='lines')\n",
    "frames_=[]\n",
    "for frame in frames:\n",
    "    frames_.append(frame)\n",
    "frames=frames_\n",
    "tear=tears[index][temp_set]\n",
    "if tear is not None:\n",
    "    for correction in tear:\n",
    "        frame_new=np.array(frames[correction[0]])\n",
    "        frame_new[correction[1],:]=(frame_new[correction[1]+1,:]+frame_new[correction[1]-1,:])/2\n",
    "        frame_new = (frame_new - frame_new.min()) / (frame_new.max() - frame_new.min())  # scale to [0, 1]\n",
    "        frame_new = frame_new * 2 - 1    \n",
    "        frame_new = pims.Frame(frame_new, frame_no=correction[0])\n",
    "        frames[correction[0]]=frame_new\n",
    "images=[]\n",
    "for frame in range(len(frames)): #change len(frames) to a number to see a smaller set of images\n",
    "    image=fc.add_crop(frames[frame],0,0,frame_drift_pars[0][index]['output_crop'])\n",
    "    molecule_size=7\n",
    "    kwaargs={\n",
    "        \"minmass\" : 2, #integrated intensity of feature\n",
    "        \"separation\" : 1, #How far apart \n",
    "        \"threshold\":0.12,} #lowest intensity the program sees, everything is normalized -1 to 1.\n",
    "        #Most useful for getting rid of grey padded caused particles is threshold \n",
    "    f = tp.locate(image,molecule_size,**kwaargs,engine='python')\n",
    "    plt.title(frame)\n",
    "    images.append(image)\n",
    "    tp.annotate(f,image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Once you have good parameters, GO BACK TO THE BEGGINING and change the parameters there.\n",
    "Run the following cell after to update everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTANT, loads some paremeters for testing SAME AS EARLIER CELL, HERE FOR CONVINIENCE\n",
    "\n",
    "ms=[]\n",
    "\n",
    "for i,emd in enumerate(emds):\n",
    "    with open('params.yaml', 'w') as f:\n",
    "        yaml.dump(params_[i], f, default_flow_style=False)\n",
    "    m = MotionAnalyzer(emd.sets, emd.voltages_temperatures,\n",
    "                   emd.folder,frame_drift_par=frame_drift_pars[i], heater=True, drift_correction = True,rotation_check=True,correct='lines')\n",
    "    ms.append(m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addding drift corrections\n",
    "The next cell uses frame_correct to stabilize the images, and the cell after plots them. Warning, this can be fairly slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN IF YOU WANT TO CHECK FRAME CORRECTION BEFOREHAND AND ADD MANUAL CORRECTIONS\n",
    "frames_all=[]\n",
    "for i,m in enumerate(ms):\n",
    "    frames_corrected=[]\n",
    "    for temp_set,path in enumerate(m.SXM_PATH):\n",
    "        frames_ = SXMReader(path, correct='lines')\n",
    "        frames=[]\n",
    "        for frame in frames_: \n",
    "            frames.append(frame)\n",
    "        tear=tears[i][temp_set]\n",
    "        if tear is not None:\n",
    "            for correction in tear:\n",
    "                plt.figure()\n",
    "                frame_new=np.array(frames[correction[0]])\n",
    "                frame_new[correction[1],:]=(frame_new[correction[1]+1,:]+frame_new[correction[1]-1,:])/2\n",
    "                frame_new = (frame_new - frame_new.min()) / (frame_new.max() - frame_new.min())  # scale to [0, 1]\n",
    "                frame_new = frame_new * 2 - 1    \n",
    "                frame_new = pims.Frame(frame_new, frame_no=correction[0])\n",
    "                frames[correction[0]]=frame_new\n",
    "                plt.imshow(frame_new)\n",
    "                plt.show()\n",
    "        frames_=frames\n",
    "\n",
    "        frames_corrected.append(fc.Frame_correct_loop(frames_,m.PARAMS[temp_set],**frame_drift_par)) #uses default parameters\n",
    "    frames_all.append(frames_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot trajectories to check for errors\n",
    "index=0 #CHANGE THIS TO BE THE INDEX OF THE DATASET YOU'RE INTERSTED IN\n",
    "temp_set=1\n",
    "frames_corrected=frames_all[index][temp_set] \n",
    "molecule_size, min_mass, max_mass, separation, min_size, max_ecc, adaptive_stop, search_range,threshold, _ = ms[index].PARAMS[temp_set]\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.rcParams['figure.dpi'] = 150  \n",
    "plt.ioff()\n",
    "fig=plt.figure(figsize=(8, 6), dpi=120)\n",
    "ax1=plt.axes(xlim=(0, 256), ylim=(0, 256), frameon=False)\n",
    "plt.axis('off')\n",
    "ln, = ax1.plot([], [], lw=3)\n",
    "f=tp.batch(frames_corrected,molecule_size,minmass=min_mass,separation=separation,threshold=threshold,engine='python')\n",
    "t = tp.link(f, search_range=search_range, adaptive_stop=adaptive_stop,memory=0)\n",
    "def animate(i):\n",
    "    plt.cla()\n",
    "    plt.title(i)\n",
    "    tp.plot_traj(t[(t['frame'])<=i], superimpose=frames_corrected[i], label=True, ax=ax1, plot_style={'alpha' : 1});\n",
    "    ax1.set_prop_cycle(color=['g', 'r', 'c', 'm', 'y', 'k'])\n",
    "line_ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(frames_corrected))\n",
    "plt.close()\n",
    "line_ani\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Correction\n",
    "Sometimes the frame_correct doesnt converge properly, or converges to the wrong conclusion (i.e if we have a periodic background, it might \n",
    "be off by a lattice constant). The next cell should let you measure the offset: click a stationary point in each frame. (This might not work if you are on a remote server because of how the popup works). It will open a window where you click a point on the left and on the right that is stationary between the two images, and it will measure the shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running this cell should open up a window\n",
    "dataset = 0\n",
    "temp_set = 1\n",
    "shift_frames = [] #Frames after shifts\n",
    "measured_shifts=[]\n",
    "for frame in shift_frames:\n",
    "    measured = fc.measure_shift(frames_all[dataset][temp_set], frame)\n",
    "    measured_shifts.append(measured)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This cell confirms your selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN THIS TO CONFIRM MANUAL CORRECTION\n",
    "frame_drift_pars[dataset][temp_set]['adjust']=[[],[]] #Resets\n",
    "frame_drift_pars[dataset][temp_set]['adjust']=[shift_frames,measured_shifts] #This adds the previously calculated shift,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIONAL:The next two cells add and animate your manual selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_manual=[]\n",
    "for i,m in enumerate(ms):\n",
    "    frames_corrected=[]\n",
    "    for temp_set,path in enumerate(m.SXM_PATH):\n",
    "        frames_ = SXMReader(path, correct='lines')\n",
    "        frames=[]\n",
    "        for frame in frames_: \n",
    "            frames.append(frame)\n",
    "        tear=tears[i][temp_set]\n",
    "        if tear is not None:\n",
    "            for correction in tear:\n",
    "                plt.figure()\n",
    "                frame_new=np.array(frames[correction[0]])\n",
    "                frame_new[correction[1],:]=(frame_new[correction[1]+1,:]+frame_new[correction[1]-1,:])/2\n",
    "                frame_new = (frame_new - frame_new.min()) / (frame_new.max() - frame_new.min())  # scale to [0, 1]\n",
    "                frame_new = frame_new * 2 - 1    \n",
    "                frame_new = pims.Frame(frame_new, frame_no=correction[0])\n",
    "                frames[correction[0]]=frame_new\n",
    "                plt.imshow(frame_new)\n",
    "                plt.show()\n",
    "        frames_=frames\n",
    "\n",
    "        frames_corrected.append(fc.Frame_correct_loop(frames_,m.PARAMS[temp_set],**frame_drift_pars[dataset][temp_set]))\n",
    "    frames_manual.append(frames_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot trajectories to check for errors\n",
    "index=0 #CHANGE THIS TO BE THE INDEX OF THE DATASET YOU'RE INTERSTED IN\n",
    "temp_set=1\n",
    "frames_corrected=frames_manual[index][temp_set] \n",
    "molecule_size, min_mass, max_mass, separation, min_size, max_ecc, adaptive_stop, search_range,threshold, _ = ms[index].PARAMS[temp_set]\n",
    "\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.rcParams['figure.dpi'] = 150  \n",
    "plt.ioff()\n",
    "fig=plt.figure(figsize=(8, 6), dpi=120)\n",
    "ax1=plt.axes(xlim=(0, 256), ylim=(0, 256), frameon=False)\n",
    "plt.axis('off')\n",
    "ln, = ax1.plot([], [], lw=3)\n",
    "f=tp.batch(frames_corrected,molecule_size,minmass=min_mass,separation=separation,threshold=threshold,engine='python')\n",
    "t = tp.link(f, search_range=search_range, adaptive_stop=adaptive_stop,memory=0)\n",
    "def animate(i):\n",
    "    plt.cla()\n",
    "    plt.title(i)\n",
    "    tp.plot_traj(t[(t['frame'])<=i], superimpose=frames_corrected[i], label=True, ax=ax1, plot_style={'alpha' : 1});\n",
    "    ax1.set_prop_cycle(color=['g', 'r', 'c', 'm', 'y', 'k'])\n",
    "line_ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(frames_corrected))\n",
    "plt.close()\n",
    "line_ani\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional but recommended: Add info back to beggining\n",
    "In the beggining, we did \n",
    "\n",
    "frame_drift_pars.append([frame_drift_par,frame_drift_par])\n",
    "\n",
    "which puts the default no manual adjustment.\n",
    "If you want to record the manual adjustment so you don't have to do them again, record use the following format at the beginning instead:\n",
    "\n",
    "frame_drift_par_0={\n",
    "\n",
    "                   'steps':2,\n",
    "                   \n",
    "                   'adjust':[[1],[(-1.3,-24)]],\n",
    "                   \n",
    "                   'output_crop':200, \n",
    "} \n",
    "\n",
    "frame_drift_par_1={\n",
    "\n",
    "                   'steps':2,\n",
    "                   \n",
    "                   'adjust':[[shift_frame1,shiftframe2,shiftframe3,etc],[(shiftx,shifty),(shiftx,shifty),(shiftx,shifty),etc]],\n",
    "                   \n",
    "                   'output_crop':200, \n",
    "} \n",
    "\n",
    "frame_drift_pars.append(frame_drift_par_0,frame_drift_par_1).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now We look at the final product.\n",
    "Run the next cell to put everything together with some additional filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms=[]\n",
    "\n",
    "for i,emd in enumerate(emds):\n",
    "    with open('params.yaml', 'w') as f:\n",
    "        yaml.dump(params_[i], f, default_flow_style=False)\n",
    "    m = MotionAnalyzer(emd.sets, emd.voltages_temperatures,\n",
    "                   emd.folder,frame_drift_par=frame_drift_pars[i], heater=True, drift_correction = False,rotation_check=True,correct='lines')\n",
    "    if tears[i] is not None:\n",
    "        m.tear_correct=tears[i]\n",
    "    m.analyze()\n",
    "    ms.append(m)\n",
    "dps=[]\n",
    "for i,m in enumerate(ms):\n",
    "    dp=DiffusionPlotter(m)\n",
    "    dps.append(dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell animates the final trajectories\n",
    "The animations are saved to the analysis folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot trajectories to check for errors\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.rcParams['figure.dpi'] = 150  \n",
    "plt.ioff()\n",
    "fig=plt.figure(figsize=(8, 6), dpi=120)\n",
    "ax1=plt.axes(xlim=(0, 256), ylim=(0, 256), frameon=False)\n",
    "plt.axis('off')\n",
    "ln, = ax1.plot([], [], lw=3)\n",
    "dataset=ms[0]##CHOOSE DATAFRAME HERE \n",
    "temp_index=0\n",
    "t=dataset.t3s_C[0][temp_index] #DRIFT UNCORRECTED TO PROPERLY MATCH IMAGE\n",
    "ax1.set_prop_cycle(color=['g', 'r', 'c', 'm', 'y', 'k'])\n",
    "def animate(i):\n",
    "    plt.cla()\n",
    "    plt.title(i)\n",
    "\n",
    "    tp.plot_traj(t[(t['frame']<=i)], superimpose=dataset.frames[temp_index][i], label=True, ax=ax1, plot_style={'alpha' : 1})\n",
    "    ax1.set_prop_cycle(color=['g', 'r', 'c', 'm', 'y', 'k'])\n",
    "#     plt.imshow(frames[i], cmap='gray')\n",
    "# Set up formatting for the movie files\n",
    "Writer = matplotlib.animation.writers['ffmpeg']\n",
    "writer = Writer(fps=5, metadata=dict(artist='Me'), bitrate=1800)\n",
    "line_ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(dataset.frames[temp_index]))\n",
    "line_ani.save(f'{dataset.ANALYSIS_FOLDER}_tracking.mp4', writer=writer)\n",
    "line_ani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following cell is to manually remove any particles. \n",
    "Ideally you shouldn't have to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVING PARTICLES\n",
    "index=0\n",
    "\n",
    "bad_particles_for_first_temp=[2000,3000] #This is just for clarity, you are not limited to two tempuratures. \n",
    "bad_particles_for_second_temp=[123123123,345435]\n",
    "ms[index].removed_particles=[bad_particles_for_first_temp,bad_particles_for_second_temp] \n",
    "\n",
    "ms[index].analyze(refilter=True) #Removes them and recalculates \n",
    "dps[index]=DiffusionPlotter(ms[index]) #updates the plotter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The nexts cells shows how the data is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=0\n",
    "temp_set=0\n",
    "data=ms[dataset]#all data stored in the list ms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t3s has all the data from trackpy: if you want to make plots or do data analysis, this is where to look.\n",
    "#The values are in PIXELS. Multiply by data.NM_PER_PIXEL to get physical values\n",
    "data.t3s[temp_set] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t3s_C has both the ensemble drift subtracted and not subtracted, i=0 is raw and i=1 is drift subtracted. Any attribute with _C is structured similarly.\n",
    "#t3s is just i=0 or 1 depending on what you chose when m was initialized \n",
    "i=0\n",
    "data.t3s_C[i][temp_set] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are many values already calculated, stored as attributes.\n",
    "They follow similar organization:\n",
    "\n",
    "data.attribute[temp_set], \n",
    "and \n",
    "\n",
    "data.attribute_C[drift_corrected][temp_set].\n",
    "\n",
    "Look at analysis_stm.py for more detailed description. Below I have printed all the attribute names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for key in m.__dict__.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DiffusionPlotter\n",
    "DiffusionPlotter is a class that stores a bunch of plotting functions. We create instances of this class in the list named dps. \n",
    "More detail is in analysis_stm.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=0\n",
    "temp_set=0\n",
    "plotter=dps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots msd vs timestep. scale is either 'linear' or 'log'\n",
    "#It is fitted using d*(x^a)+c. linearfit=True forces a=1, and intercept=False forces c=0. end takes an integer and cuts off after that point. \n",
    "#Note that the points at later time have higher errors associated, because there are less data points for that time scale\n",
    "plotter.plot_msd(scale='linear',linearfit=False,intercept=False,end=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All the available functions are printed below. Look at analysis_stm.py for how to use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "methods=[\n",
    "    name for name, obj in DiffusionPlotter.__dict__.items()\n",
    "    if inspect.isfunction(obj) and not name.startswith('_')\n",
    "]\n",
    "for method in methods:\n",
    "    print(method)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elmloc_test_kernel",
   "language": "python",
   "name": "elmloc_test_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
