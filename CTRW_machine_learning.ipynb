{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# This Notebook shows how to do AI CTRW classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Run the following cells to get all the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython magic commands\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Third-party numerical/scientific imports\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Data analysis and tracking\n",
    "import trackpy as tp\n",
    "import yaml\n",
    "\n",
    "# Image processing\n",
    "from PIL import Image\n",
    "\n",
    "# Plotting and visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Interactive widgets\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# TensorFlow/Keras\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Custom modules\n",
    "from analysis_stm import MotionAnalyzer, ExpMetaData, DiffusionPlotter\n",
    "from sxmreader import SXMReader\n",
    "import frame_correct as fc\n",
    "from monet.src.classification_net_training_input import create_ctrw_model\n",
    "import keras_utils as ku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sets some parameters\n",
    "frame_drift_par={\n",
    "                   'steps':2,\n",
    "                   'adjust':[[],[]],\n",
    "                   'output_crop':250,                      \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Sets up parameters and file path to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "emds=[]\n",
    "frame_drift_pars=[]\n",
    "tears=[]\n",
    "params_=[]\n",
    "\n",
    "Vg=60\n",
    "FOLDER = \"test_sets/15.5K\"\n",
    "voltages_temperatures = np.array([15.5])\n",
    "\n",
    "sets = [ range(138, 156),]\n",
    "emd = ExpMetaData(sets, Vg, voltages_temperatures, FOLDER)\n",
    "\n",
    "\n",
    "params = {\n",
    "    'molecule_size': 7,\n",
    "    'min_mass': 2,\n",
    "    'max_mass': 100,\n",
    "    'min_size': 1,\n",
    "    'max_ecc': 1,\n",
    "    'separation': 1,\n",
    "    'search_range': 50,\n",
    "    'adaptive_stop': 1,\n",
    "    'diffusion_time': 10,\n",
    "    'threshold': 0.12,\n",
    "}\n",
    "\n",
    "frame_drift_pars.append([frame_drift_par])\n",
    "emds.append(emd)\n",
    "tears.append([[[0,64],[10,61]]]) \n",
    "params_.append(params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads in and analyzes data\n",
    "\n",
    "ms=[]\n",
    "\n",
    "for i,emd in enumerate(emds):\n",
    "    with open('params.yaml', 'w') as f:\n",
    "        yaml.dump(params_[i], f, default_flow_style=False)\n",
    "    m = MotionAnalyzer(emd.sets, emd.voltages_temperatures,\n",
    "                   emd.folder,frame_drift_par=frame_drift_pars[i], heater=True, drift_correction = False,rotation_check=True,correct='lines')\n",
    "    if tears[i] is not None:\n",
    "        m.tear_correct=tears[i]\n",
    "    m.analyze()\n",
    "    ms.append(m)\n",
    "dps=[]\n",
    "for i,m in enumerate(ms):\n",
    "    dp=DiffusionPlotter(m)\n",
    "    dps.append(dp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### This cell plots trajectories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.rcParams['figure.dpi'] = 150  \n",
    "plt.ioff()\n",
    "fig=plt.figure(figsize=(8, 6), dpi=120)\n",
    "ax1=plt.axes(xlim=(0, 256), ylim=(0, 256), frameon=False)\n",
    "plt.axis('off')\n",
    "ln, = ax1.plot([], [], lw=3)\n",
    "index=0\n",
    "dataset=ms[index]##CHOOSE DATAFRAME HERE \n",
    "\n",
    "temp_set=0\n",
    "t=dataset.t3s_C[0][temp_set] #DRIFT UNCORRECTED TO PROPERLY MATCH IMAGE\n",
    "ax1.set_prop_cycle(color=['g', 'r', 'c', 'm', 'y', 'k'])\n",
    "def animate(i):\n",
    "    plt.cla()\n",
    "    plt.title(i)\n",
    "\n",
    "    tp.plot_traj(t[(t['frame']<=i)], superimpose=dataset.frames[temp_set][i], label=True, ax=ax1, plot_style={'alpha' : 1})\n",
    "    ax1.set_prop_cycle(color=['g', 'r', 'c', 'm', 'y', 'k'])\n",
    "\n",
    "line_ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(dataset.frames[temp_set]))\n",
    "line_ani\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Machine Learning Part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "#### If model doesnt exist run this cell to create one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=[14,17] #Chooses the temperature range the model is trained on\n",
    "step=18 #Chooses the amount of steps for the model input\n",
    "epochs=50 #The amount of training epochs\n",
    "net_file=f'models/{step}_{temp[0]}_{temp[1]}_ep{epochs}_class_model.h5' #savefile name.\n",
    "print(net_file[:-3])\n",
    "if os.path.exists(net_file):\n",
    "    print('File already exists')\n",
    "else:\n",
    "    create_ctrw_model(step,net_file,temp_range=temp,epochs=epochs,)\n",
    "model=load_model(net_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Run the next 2 cells to define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this, function to choose certain trajectory lengths\n",
    "\n",
    "def trim_trajectories(t_, steps, crop_from='start'):\n",
    "    t = t_.copy()\n",
    "    particle_counts = t.groupby('particle')['frame'].count()\n",
    "    good_particles = particle_counts[particle_counts >= steps].index\n",
    "    t = t[t['particle'].isin(good_particles)]\n",
    "\n",
    "    if crop_from == 'start':\n",
    "        first_frames = t.groupby('particle')['frame'].min()\n",
    "        final_frames = first_frames + steps - 1\n",
    "        final_frames_dict = final_frames.to_dict()\n",
    "        t = t[t.apply(lambda row: row['frame'] <= final_frames_dict[row['particle']], axis=1)]\n",
    "\n",
    "    elif crop_from == 'end':\n",
    "        final_frames = t.groupby('particle')['frame'].max()\n",
    "        first_frames = final_frames - steps + 1\n",
    "        first_frames_dict = first_frames.to_dict()\n",
    "        t = t[t.apply(lambda row: row['frame'] >= first_frames_dict[row['particle']], axis=1)]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"crop_from must be either 'start' or 'end'\")\n",
    "\n",
    "    particle_counts_final = t.groupby('particle')['frame'].count()\n",
    "    assert (particle_counts_final == steps).all(), \"Not all trajectories have exactly 'steps' frames!\"\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A check for a weird trackpy bug, should have not particles with discontinuities\n",
    "def check_frame_discontinuities(t):\n",
    "    discontinuous_particles = []\n",
    "    for particle, group in t.groupby('particle'):\n",
    "        frames = np.sort(group['frame'].values)\n",
    "        diffs = np.diff(frames)\n",
    "        if np.any(diffs > 1):\n",
    "            discontinuous_particles.append((particle, frames, diffs[diffs > 1]))\n",
    "    return discontinuous_particles\n",
    "for m in ms:\n",
    "    discontinuities = check_frame_discontinuities(m.t3s_C[0][0])\n",
    "    print(f\"Particles with discontinuities: {[d[0] for d in discontinuities]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Run the next cell to use the machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does classification and then makes pie chart, saved as png\n",
    "#classifications are saved in new collumn in data frame t4 in list t4s[]\n",
    "\n",
    "# Define color map and label mapping\n",
    "colors = [np.array([1,0,0]), np.array([0,0,1]), np.array([0,1,0])]\n",
    "diff_class = {0: 'fbm', 1: 'brownian', 2: 'ctrw'}\n",
    "labels = ['fbm', 'brownian', 'ctrw']\n",
    "titles = [m_.SXM_PATH[0][0].strip(\"/\").split(\"/\")[1] for m_ in ms]\n",
    "\n",
    "# Classification function\n",
    "def classify(df, steps=step, model=model):\n",
    "    x = df.x.values\n",
    "    dx = ku.generate_dx(x)\n",
    "    value, prediction = ku.classification_on_real(dx, steps=steps, model=model)\n",
    "    df['class'] = diff_class[prediction]\n",
    "    df['fbm_prob'], df['brownian_prob'], df['ctrw_prob'] = value[0], value[1], value[2]\n",
    "    return df\n",
    "\n",
    "# Prepare storage\n",
    "results_start = {'fbm': {}, 'brownian': {}, 'ctrw': {}}\n",
    "results_end = {'fbm': {}, 'brownian': {}, 'ctrw': {}}\n",
    "\n",
    "print(f\"Processing model: {net_file}\")\n",
    "for i in range(len(ms)):\n",
    "    t4s=[]    \n",
    "    print(f\"  Dataset {i}\")\n",
    "    for t3 in ms[i].t3s:\n",
    "        t4 = trim_trajectories(t3, steps=step, crop_from='end') ## CHANGE END TO START to choose which side to trim trajectories\n",
    "        t4 = t4.groupby('particle', group_keys=False).apply(classify, steps=step, model=model)    \n",
    "        t4s.append(t4)\n",
    "        if np.shape(t4)[0]==0:\n",
    "            continue\n",
    "        # Compute class probabilities\n",
    "        fbm_mean = t4.groupby('particle')['fbm_prob'].mean().mean()\n",
    "        brownian_mean = t4.groupby('particle')['brownian_prob'].mean().mean()\n",
    "        ctrw_mean = t4.groupby('particle')['ctrw_prob'].mean().mean()\n",
    "        # Pie chart\n",
    "        sizes = [fbm_mean, brownian_mean, ctrw_mean]\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.pie(sizes, labels=labels, colors=colors,\n",
    "                autopct='%1.1f%%', startangle=140, textprops={'fontsize': 20})\n",
    "        plt.title(f\"{titles[i]}\", fontsize=25)\n",
    "        plt.axis('equal')  # Equal aspect ratio ensures pie is round.\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{ms[i].ANALYSIS_FOLDER}/{titles[i]}_ctrw.png\") #Saves to analysis folder, can change this if you want \n",
    "    ms[i].t4s=t4s\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Run the next cell to create movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates movies with trajectories colored by classification\n",
    "line_anis=[]\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.rcParams['figure.dpi'] = 150  \n",
    "plt.ioff()\n",
    "\n",
    "for index in range(len(ms)):\n",
    "    dataset = ms[index]\n",
    "    temp_index = 0\n",
    "    t = t4s[index]\n",
    "    if np.shape(t)[0] == 0:\n",
    "        continue\n",
    "    frames = dataset.frames[temp_index]\n",
    "\n",
    "    # ---- Assign colors ----\n",
    "    color_dict = {\n",
    "        'ctrw_prob': np.array([0, 1, 0]),\n",
    "        'fbm_prob': np.array([1, 0, 0]),\n",
    "        'brownian_prob': np.array([0, 0, 1])\n",
    "    }\n",
    "\n",
    "    color_map = {}\n",
    "    for pid in t['particle'].unique():\n",
    "        traj_row = t[t['particle'] == pid].iloc[0]\n",
    "        probs = {\n",
    "            'ctrw_prob': traj_row['ctrw_prob'],\n",
    "            'fbm_prob': traj_row['fbm_prob'],\n",
    "            'brownian_prob': traj_row['brownian_prob']\n",
    "        }\n",
    "        dominant_type = max(probs, key=probs.get)\n",
    "        prob_value = probs[dominant_type]\n",
    "        intensity = max(0, (prob_value - 0.33) / (1 - 0.33))\n",
    "        base_color = color_dict[dominant_type]\n",
    "        final_color = (1 - intensity) * np.array([1, 1, 1]) + intensity * base_color\n",
    "        color_map[pid] = final_color\n",
    "\n",
    "    particle_trajectories = {\n",
    "        pid: df for pid, df in t.groupby('particle')\n",
    "    }\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 6), dpi=120)\n",
    "    ax1.set_xlim(0, 256)\n",
    "    ax1.set_ylim(0, 256)\n",
    "    ax1.axis('off')\n",
    "\n",
    "    legend_elements = [\n",
    "        Patch(facecolor=color_dict['ctrw_prob'], edgecolor='black', label='CTRW'),\n",
    "        Patch(facecolor=color_dict['fbm_prob'], edgecolor='black', label='FBM'),\n",
    "        Patch(facecolor=color_dict['brownian_prob'], edgecolor='black', label='Brownian')\n",
    "    ]\n",
    "    ax1.legend(\n",
    "        handles=legend_elements,\n",
    "        loc='upper right',\n",
    "        frameon=True,\n",
    "        framealpha=0.8,\n",
    "        edgecolor='black',\n",
    "        fontsize=9\n",
    "    )\n",
    "\n",
    "    img_handle = ax1.imshow(frames[0], cmap='gray')\n",
    "\n",
    "    # ---- Animation function ----\n",
    "    def animate(i):\n",
    "        img_handle.set_data(frames[i])\n",
    "        ax1.set_title(f\"{titles[index]} Frame {i}\")\n",
    "        while ax1.lines:\n",
    "            ax1.lines[0].remove()\n",
    "        for pid, traj in particle_trajectories.items():\n",
    "            traj_up_to_i = traj[traj['frame'] <= i]\n",
    "            if not traj_up_to_i.empty:\n",
    "                ax1.plot(traj_up_to_i['x'], traj_up_to_i['y'], lw=1, color=color_map[pid])\n",
    "\n",
    "    # ---- Create and save animation ----\n",
    "    line_ani = matplotlib.animation.FuncAnimation(\n",
    "        fig, animate, frames=len(frames)\n",
    "    )\n",
    "    Writer = matplotlib.animation.writers['ffmpeg'] \n",
    "    line_ani.save(f\"{dataset.ANALYSIS_FOLDER}/{titles[index]}_ctrw.mp4\") #Saves to analysis folder, can change this if you want \n",
    "    line_ani\n",
    "    line_anis.append(line_ani)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_anis[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Group by particle → take first row for each particle\n",
    "for index in range(len(ms)):\n",
    "    t4 = t4s[index]\n",
    "    if np.shape(t4)[0]==0:\n",
    "        continue\n",
    "    particle_groups = t4.groupby('particle').first()\n",
    "    \n",
    "    # For each particle, find max probability and its type\n",
    "    classifications = particle_groups[['ctrw_prob', 'fbm_prob', 'brownian_prob']].idxmax(axis=1)\n",
    "    max_probs = particle_groups[['ctrw_prob', 'fbm_prob', 'brownian_prob']].max(axis=1)\n",
    "    \n",
    "    # Filter particles with max prob > 0.40\n",
    "    filtered = classifications[max_probs > 0.40]\n",
    "    \n",
    "    # Count how many particles in each classification\n",
    "    counts = filtered.value_counts()\n",
    "    print(titles[index])\n",
    "    print(counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Group by particle → take first row for each particle\n",
    "for index in range(len(ms)):\n",
    "    t5 = t5s[index]\n",
    "    if np.shape(t5)[0]==0:\n",
    "        continue\n",
    "    particle_groups = t5.groupby('particle').first()\n",
    "    \n",
    "    # For each particle, find max probability and its type\n",
    "    classifications = particle_groups[['ctrw_prob', 'fbm_prob', 'brownian_prob']].idxmax(axis=1)\n",
    "    max_probs = particle_groups[['ctrw_prob', 'fbm_prob', 'brownian_prob']].max(axis=1)\n",
    "    \n",
    "    # Filter particles with max prob > 0.40\n",
    "    filtered = classifications[max_probs > 0.50]\n",
    "    \n",
    "    # Count how many particles in each classification\n",
    "    counts = filtered.value_counts()\n",
    "    print(titles[index])\n",
    "    print(counts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elmloc_test2_kernel",
   "language": "python",
   "name": "elmloc_test2_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
